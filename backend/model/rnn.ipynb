{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 12s 19ms/step - loss: 0.1676 - accuracy: 0.9200 - val_loss: 0.0816 - val_accuracy: 0.9638\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0732 - accuracy: 0.9655 - val_loss: 0.1079 - val_accuracy: 0.9544\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0732 - accuracy: 0.9639 - val_loss: 0.0890 - val_accuracy: 0.9531\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0632 - accuracy: 0.9673 - val_loss: 0.0704 - val_accuracy: 0.9638\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0756 - accuracy: 0.9633 - val_loss: 0.0787 - val_accuracy: 0.9619\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0637 - accuracy: 0.9666 - val_loss: 0.0731 - val_accuracy: 0.9638\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0731 - accuracy: 0.9620 - val_loss: 0.0674 - val_accuracy: 0.9638\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0588 - accuracy: 0.9680 - val_loss: 0.0700 - val_accuracy: 0.9638\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0618 - accuracy: 0.9673 - val_loss: 0.0700 - val_accuracy: 0.9638\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0597 - accuracy: 0.9680 - val_loss: 0.0683 - val_accuracy: 0.9638\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0685 - accuracy: 0.9650 - val_loss: 0.0687 - val_accuracy: 0.9638\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0586 - accuracy: 0.9675 - val_loss: 0.0680 - val_accuracy: 0.9638\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0594 - accuracy: 0.9675 - val_loss: 0.0809 - val_accuracy: 0.9638\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0596 - accuracy: 0.9678 - val_loss: 0.0695 - val_accuracy: 0.9638\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0641 - accuracy: 0.9661 - val_loss: 0.0858 - val_accuracy: 0.9638\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0659 - accuracy: 0.9656 - val_loss: 0.1369 - val_accuracy: 0.9031\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0692 - accuracy: 0.9620 - val_loss: 0.0732 - val_accuracy: 0.9638\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0601 - accuracy: 0.9680 - val_loss: 0.0733 - val_accuracy: 0.9638\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.0606 - accuracy: 0.9670 - val_loss: 0.0706 - val_accuracy: 0.9638\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0597 - accuracy: 0.9669 - val_loss: 0.0775 - val_accuracy: 0.9638\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0620 - accuracy: 0.9673 - val_loss: 0.0722 - val_accuracy: 0.9638\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0575 - accuracy: 0.9672 - val_loss: 0.0734 - val_accuracy: 0.9638\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0590 - accuracy: 0.9686 - val_loss: 0.0678 - val_accuracy: 0.9638\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0634 - accuracy: 0.9675 - val_loss: 0.0837 - val_accuracy: 0.9638\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0597 - accuracy: 0.9681 - val_loss: 0.0813 - val_accuracy: 0.9638\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0615 - accuracy: 0.9670 - val_loss: 0.0974 - val_accuracy: 0.9606\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0634 - accuracy: 0.9664 - val_loss: 0.0805 - val_accuracy: 0.9644\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0578 - accuracy: 0.9684 - val_loss: 0.0748 - val_accuracy: 0.9638\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0596 - accuracy: 0.9681 - val_loss: 0.0813 - val_accuracy: 0.9631\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0557 - accuracy: 0.9680 - val_loss: 0.1020 - val_accuracy: 0.9638\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0570 - accuracy: 0.9675 - val_loss: 0.0843 - val_accuracy: 0.9638\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0622 - accuracy: 0.9677 - val_loss: 0.0770 - val_accuracy: 0.9650\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0600 - accuracy: 0.9670 - val_loss: 0.0714 - val_accuracy: 0.9638\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0581 - accuracy: 0.9677 - val_loss: 0.0755 - val_accuracy: 0.9638\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0584 - accuracy: 0.9684 - val_loss: 0.0901 - val_accuracy: 0.9644\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0599 - accuracy: 0.9677 - val_loss: 0.0749 - val_accuracy: 0.9638\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0571 - accuracy: 0.9680 - val_loss: 0.1052 - val_accuracy: 0.9638\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0561 - accuracy: 0.9689 - val_loss: 0.1022 - val_accuracy: 0.9638\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0561 - accuracy: 0.9684 - val_loss: 0.0865 - val_accuracy: 0.9638\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0553 - accuracy: 0.9683 - val_loss: 0.0825 - val_accuracy: 0.9638\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0541 - accuracy: 0.9691 - val_loss: 0.0933 - val_accuracy: 0.9638\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0553 - accuracy: 0.9683 - val_loss: 0.0911 - val_accuracy: 0.9638\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0558 - accuracy: 0.9683 - val_loss: 0.0946 - val_accuracy: 0.9638\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0554 - accuracy: 0.9681 - val_loss: 0.1038 - val_accuracy: 0.9650\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0625 - accuracy: 0.9680 - val_loss: 0.0875 - val_accuracy: 0.9625\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0594 - accuracy: 0.9677 - val_loss: 0.1063 - val_accuracy: 0.9638\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0560 - accuracy: 0.9675 - val_loss: 0.0953 - val_accuracy: 0.9638\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0602 - accuracy: 0.9677 - val_loss: 0.0923 - val_accuracy: 0.9638\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 2s 11ms/step - loss: 0.0579 - accuracy: 0.9675 - val_loss: 0.0971 - val_accuracy: 0.9638\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0567 - accuracy: 0.9686 - val_loss: 0.1056 - val_accuracy: 0.9638\n",
      "\n",
      "RNN Model Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98      1376\n",
      "           1       0.91      1.00      0.95       624\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.95      0.98      0.96      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n",
      "Accuracy: 0.9675\n",
      "RNN model and preprocessor exported as 'rnn_model_simplified.h5' and 'preprocessor_simplified.pkl'\n",
      "Isolation Forest model saved as 'anomaly_model_simplified.pkl'\n",
      "\n",
      "Test Case Result:\n",
      "Denied - Model prediction\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('synthetic_access_data_10000.csv')\n",
    "\n",
    "# Step 1: Select 6 key features\n",
    "selected_features = [\n",
    "    'user_role', 'department', 'employee_status', \n",
    "    'resource_sensitivity', 'request_reason', 'past_violations'\n",
    "]\n",
    "target = 'is_approved'\n",
    "\n",
    "# Step 2: Clean the dataset\n",
    "df = df.dropna(subset=selected_features + [target])\n",
    "df = df[df['past_violations'] <= 50]  # Cap past_violations at 50\n",
    "\n",
    "# Step 3: Prepare features and target\n",
    "X = df[selected_features]\n",
    "y = df[target]\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_cols = ['user_role', 'department', 'employee_status', 'resource_sensitivity', 'request_reason']\n",
    "numeric_cols = ['past_violations']\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "        ('num', 'passthrough', numeric_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Split data BEFORE preprocessing\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train = preprocessor.fit_transform(X_train_raw)\n",
    "X_test = preprocessor.transform(X_test_raw)\n",
    "feature_names = (preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols).tolist() + \n",
    "                 numeric_cols)\n",
    "\n",
    "# Reshape data for RNN (samples, timesteps, features)\n",
    "n_features = X_train.shape[1]\n",
    "X_train_rnn = X_train.reshape((X_train.shape[0], 1, n_features))\n",
    "X_test_rnn = X_test.reshape((X_test.shape[0], 1, n_features))\n",
    "\n",
    "# Step 4: Define and Train RNN Model\n",
    "def build_rnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(1, n_features), return_sequences=True))  # First LSTM layer\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(64, return_sequences=False))  # Second LSTM layer\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train the RNN model\n",
    "rnn_model = build_rnn_model()\n",
    "rnn_model.fit(\n",
    "    X_train_rnn, y_train, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_proba = rnn_model.predict(X_test_rnn, verbose=0)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "print(\"\\nRNN Model Test Set Performance:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# Save the RNN model\n",
    "rnn_model.save('rnn_model_simplified.h5')\n",
    "with open('preprocessor_simplified.pkl', 'wb') as preprocessor_file:\n",
    "    pickle.dump(preprocessor, preprocessor_file)\n",
    "print(\"RNN model and preprocessor exported as 'rnn_model_simplified.h5' and 'preprocessor_simplified.pkl'\")\n",
    "\n",
    "# Step 5: Train Isolation Forest on Approved Cases\n",
    "approved_data = df[df['is_approved'] == 1][selected_features]\n",
    "X_approved_transformed = preprocessor.transform(approved_data)\n",
    "\n",
    "anomaly_model = IsolationForest(contamination=0.1, random_state=42)\n",
    "anomaly_model.fit(X_approved_transformed)\n",
    "\n",
    "# Save Isolation Forest model\n",
    "joblib.dump(anomaly_model, 'anomaly_model_simplified.pkl')\n",
    "print(\"Isolation Forest model saved as 'anomaly_model_simplified.pkl'\")\n",
    "\n",
    "# Step 6: Test Prediction Function\n",
    "def predict_permission(request, preprocessor, rnn_model, anomaly_model):\n",
    "    request_df = pd.DataFrame([request])\n",
    "    X_req = request_df[selected_features]\n",
    "    X_req_processed = preprocessor.transform(X_req)\n",
    "    X_req_rnn = X_req_processed.reshape((1, 1, n_features))\n",
    "    \n",
    "    # Rule-based checks\n",
    "    if request.get('employee_status') == 'Terminated' and request.get('resource_sensitivity') in ['restricted', 'confidential']:\n",
    "        return \"Denied - Terminated employee\"\n",
    "    if request.get('request_reason') == 'Personal use' and request.get('resource_sensitivity') in ['restricted', 'confidential']:\n",
    "        return \"Denied - Personal use not allowed\"\n",
    "    \n",
    "    # RNN prediction\n",
    "    rnn_pred_proba = rnn_model.predict(X_req_rnn, verbose=0)[0][0]\n",
    "    rnn_pred = 1 if rnn_pred_proba > 0.5 else 0\n",
    "    if rnn_pred == 0:\n",
    "        return \"Denied - Model prediction\"\n",
    "    \n",
    "    # Anomaly detection\n",
    "    anomaly_score = anomaly_model.predict(X_req_processed)[0]\n",
    "    if anomaly_score == -1:\n",
    "        return \"Approved but flagged as anomaly\"\n",
    "    \n",
    "    return \"Approved\"\n",
    "\n",
    "# Test case\n",
    "test_case = {\n",
    "    \"user_role\": \"Employee\", \"department\": \"Sales\", \"employee_status\": \"Full-time\",\n",
    "    \"resource_sensitivity\": \"confidential\", \"request_reason\": \"Routine check\", \"past_violations\": 10\n",
    "}\n",
    "print(\"\\nTest Case Result:\")\n",
    "print(predict_permission(test_case, preprocessor, rnn_model, anomaly_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

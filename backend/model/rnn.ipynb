{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('synthetic_access_data_10000.csv')\n",
    "\n",
    "# Step 1: Select 6 key features\n",
    "selected_features = [\n",
    "    'user_role', 'department', 'employee_status', \n",
    "    'resource_sensitivity', 'request_reason', 'past_violations'\n",
    "]\n",
    "target = 'is_approved'\n",
    "\n",
    "# Step 2: Clean the dataset\n",
    "df = df.dropna(subset=selected_features + [target])\n",
    "df = df[df['past_violations'] <= 50]  # Cap past_violations at 50\n",
    "\n",
    "# Step 3: Prepare features and target\n",
    "X = df[selected_features]\n",
    "y = df[target]\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_cols = ['user_role', 'department', 'employee_status', 'resource_sensitivity', 'request_reason']\n",
    "numeric_cols = ['past_violations']\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "        ('num', 'passthrough', numeric_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Split data BEFORE preprocessing\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train = preprocessor.fit_transform(X_train_raw)\n",
    "X_test = preprocessor.transform(X_test_raw)\n",
    "feature_names = (preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols).tolist() + \n",
    "                 numeric_cols)\n",
    "\n",
    "# Reshape data for RNN (samples, timesteps, features)\n",
    "n_features = X_train.shape[1]\n",
    "X_train_rnn = X_train.reshape((X_train.shape[0], 1, n_features))\n",
    "X_test_rnn = X_test.reshape((X_test.shape[0], 1, n_features))\n",
    "\n",
    "# Step 4: Define and Train RNN Model\n",
    "def build_rnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(1, n_features), return_sequences=True))  # First LSTM layer\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(64, return_sequences=False))  # Second LSTM layer\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train the RNN model\n",
    "rnn_model = build_rnn_model()\n",
    "rnn_model.fit(\n",
    "    X_train_rnn, y_train, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_proba = rnn_model.predict(X_test_rnn, verbose=0)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "print(\"\\nRNN Model Test Set Performance:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# Save the RNN model\n",
    "rnn_model.save('rnn_model_simplified.h5')\n",
    "with open('preprocessor_simplified.pkl', 'wb') as preprocessor_file:\n",
    "    pickle.dump(preprocessor, preprocessor_file)\n",
    "print(\"RNN model and preprocessor exported as 'rnn_model_simplified.h5' and 'preprocessor_simplified.pkl'\")\n",
    "\n",
    "# Step 5: Train Isolation Forest on Approved Cases\n",
    "approved_data = df[df['is_approved'] == 1][selected_features]\n",
    "X_approved_transformed = preprocessor.transform(approved_data)\n",
    "\n",
    "anomaly_model = IsolationForest(contamination=0.1, random_state=42)\n",
    "anomaly_model.fit(X_approved_transformed)\n",
    "\n",
    "# Save Isolation Forest model\n",
    "joblib.dump(anomaly_model, 'anomaly_model_simplified.pkl')\n",
    "print(\"Isolation Forest model saved as 'anomaly_model_simplified.pkl'\")\n",
    "\n",
    "# Step 6: Test Prediction Function\n",
    "def predict_permission(request, preprocessor, rnn_model, anomaly_model):\n",
    "    request_df = pd.DataFrame([request])\n",
    "    X_req = request_df[selected_features]\n",
    "    X_req_processed = preprocessor.transform(X_req)\n",
    "    X_req_rnn = X_req_processed.reshape((1, 1, n_features))\n",
    "    \n",
    "    # Rule-based checks\n",
    "    if request.get('employee_status') == 'Terminated' and request.get('resource_sensitivity') in ['restricted', 'confidential']:\n",
    "        return \"Denied - Terminated employee\"\n",
    "    if request.get('request_reason') == 'Personal use' and request.get('resource_sensitivity') in ['restricted', 'confidential']:\n",
    "        return \"Denied - Personal use not allowed\"\n",
    "    \n",
    "    # RNN prediction\n",
    "    rnn_pred_proba = rnn_model.predict(X_req_rnn, verbose=0)[0][0]\n",
    "    rnn_pred = 1 if rnn_pred_proba > 0.5 else 0\n",
    "    if rnn_pred == 0:\n",
    "        return \"Denied - Model prediction\"\n",
    "    \n",
    "    # Anomaly detection\n",
    "    anomaly_score = anomaly_model.predict(X_req_processed)[0]\n",
    "    if anomaly_score == -1:\n",
    "        return \"Approved but flagged as anomaly\"\n",
    "    \n",
    "    return \"Approved\"\n",
    "\n",
    "# Test case\n",
    "test_case = {\n",
    "    \"user_role\": \"Employee\", \"department\": \"Sales\", \"employee_status\": \"Full-time\",\n",
    "    \"resource_sensitivity\": \"confidential\", \"request_reason\": \"Routine check\", \"past_violations\": 10\n",
    "}\n",
    "print(\"\\nTest Case Result:\")\n",
    "print(predict_permission(test_case, preprocessor, rnn_model, anomaly_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
